<!DOCTYPE html><html><head><meta name="generator" content="Hexo 3.8.0"><meta http-equiv="content-type" content="text/html; charset=utf-8"><meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport"><meta content="yes" name="apple-mobile-web-app-capable"><meta content="black-translucent" name="apple-mobile-web-app-status-bar-style"><meta content="telephone=no" name="format-detection"><meta name="description"><title>faster-rcnn源码解读－RPN | 成长的烦恼</title><link rel="stylesheet" type="text/css" href="/css/normalize.css"><link rel="stylesheet" type="text/css" href="/css/highlight.css"><link rel="stylesheet" type="text/css" href="/css/font.css"><link rel="stylesheet" type="text/css" href="/css/noise.css"><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/font-awesome/4.5.0/css/font-awesome.min.css"><link rel="Shortcut Icon" type="image/x-icon" href="/favicon.ico"><link rel="alternate" type="application/atom+xml" href="/atom.xml"></head><body><article class="wrapper"><div class="post-main"><div class="nav"><nav class="container"><a class="sidebar-nav-item active" href="/">Home</a><a class="sidebar-nav-item" href="/archives">Archives</a></nav><div class="container post-meta"><div class="post-tags"><a class="post-tag-link" href="/tags/faster-rcnn/">faster-rcnn</a><a class="post-tag-link" href="/tags/rpn/">rpn</a></div><div class="post-time">2019-01-21</div></div></div><div class="container post-header"><h1>faster-rcnn源码解读－RPN</h1></div><div class="container post-toc"><details class="toc"><summary class="toc-accordion">Table of Contents</summary><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#rpn网络结构"><span class="toc-number">1.</span> <span class="toc-text">RPN网络结构</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#rpn网络代码解析"><span class="toc-number">2.</span> <span class="toc-text">RPN网络代码解析</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#generate-anchors-py"><span class="toc-number">2.1.</span> <span class="toc-text">generate_anchors.py</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#anchor-target-layer-py"><span class="toc-number">2.2.</span> <span class="toc-text">anchor_target_layer.py</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#proposal-layer-py"><span class="toc-number">2.3.</span> <span class="toc-text">proposal_layer.py</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#proposal-target-layer-py"><span class="toc-number">2.4.</span> <span class="toc-text">proposal_target_layer.py</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#generate-py"><span class="toc-number">2.5.</span> <span class="toc-text">generate.py</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#总结"><span class="toc-number">3.</span> <span class="toc-text">总结</span></a></li></ol></details></div><div class="container post-content"><p>faster-rcnn是经典的图片检测模型，在这个模型中，首次提出了RPN(region proposal
network)这个网络结构，用来生成候选区域。这个任务之前使用一些独立检测方案，RPN
首次使用神经网络去训练，从而使整个检测方案是端到端(end-to-end)的实现方式。这篇文章主要解读了faster-rcnn中RPN相关的代码。</p>
<h2 id="rpn网络结构"><a class="header-anchor" href="#rpn网络结构"></a>RPN网络结构</h2>
<p>RPN网络是用来生成候选框的网络，前承CNN网络的特征抽取部分，后接更具体的分类和回归模型，输入是CNN卷积层抽取的图片高维特征，输出是n个正例检测框和m个负例检测框。</p>
<p>我们可以结合<code>py-faster-rcnn</code>中的prototxt文件画出faster-rcnn网络的整体结果图和具体的rpn的结构图。</p>
<img src="/2019/faster-rcnn源码解读－RPN/rpn-Page-1.png" title="faster-rcnn网络结构图">
<p>faster-rcnn整体网络结构</p>
<img src="/2019/faster-rcnn源码解读－RPN/rpn-Page-2.png" title="RPN网络结构图">
<p>RPN网络结构</p>
<p>在卷积网络之后，RPN网络首先是又用了两层卷积网络，得到前背景二分类的分类结果和坐标回归结果，输出大小分别是2x9 , 4x9 ，9代表了每个框anchor的种类数（下文会讲到），2是分类数（0/1），4是坐标数（x1, y1, x2, y2）。</p>
<p>然后连接了<code>anchor_target_layer</code>，筛选和groundTruth匹配的anchors样本，然后后面是softmaxWithLoss层和smoothL1Loss层计算这些anchors的分类和回归损失，以学习和优化RPN的提取。</p>
<p>另一方面，在RPN的卷积层后连接了<code>proposal_layer</code>层，根据前面分类的结果筛选分类样本，然后连接<code>proposal_target_layer</code>层，生成训练样本和训练目标，接到后面的fc
层等优化loss。</p>
<p>这几个层都是用python接口写的，下面，具体结合代码看一下。</p>
<h2 id="rpn网络代码解析"><a class="header-anchor" href="#rpn网络代码解析"></a>RPN网络代码解析</h2>
<p>在faster-rcnn源码中，rpn网络相关的代码在lib/rpn目录下面，主要有这几个文件：</p>
<ol>
<li>generate_anchors.py：生成不同尺度不同大小的anchors。</li>
<li>anchor_target_layer.py：生成每个anchor的分类标签（0/1）和回归坐标。</li>
<li>proposal_layer.py：根据anchor的分类结果生成候选框集合（包括每个anchor的分类值和回归的坐标）。</li>
<li>proposal_target_layer.py：生成每个候选框的分类标签（0-k）和回归坐标。</li>
<li><a href="http://generate.py" target="_blank" rel="noopener">generate.py</a>：根据训练好的RPN网络生成检测候选集。</li>
</ol>
<p>这里面有两个概念，anchor和proposal，proposal很好理解，就是筛选出来的候选框，而
anchor，是RPN网络的一个先验结构，可以认为是候选框有多大的限定。对于一张图片，
RPN 认为需要检测的物体具有某些特定的长宽比，对这些特定的长宽比，又可以根据不同的尺度，即分辨率，得到不同的检测框，这些预先定好的检测框就被称为anchors，对这些anchors指定的区域特征进行分类和筛选，就得到proposals。</p>
<p>下面，我们分别来看这些代码，最后梳理出整个RPN的逻辑。</p>
<h3 id="generate-anchors-py"><a class="header-anchor" href="#generate-anchors-py"></a>generate_anchors.py</h3>
<p>这个文件用来生成不同大小不同分辨率的anchor框，主要的函数是<code>generate_anchors</code>。看一下它的代码：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">def generate_anchors(base_size=16, ratios=[0.5, 1, 2],</span><br><span class="line">                     scales=2**np.arange(3, 6)):</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    Generate anchor (reference) windows by enumerating aspect ratios X</span><br><span class="line">    scales wrt a reference (0, 0, 15, 15) window.</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line"></span><br><span class="line">    base_anchor = np.array([1, 1, base_size, base_size]) - 1</span><br><span class="line">    ratio_anchors = _ratio_enum(base_anchor, ratios)</span><br><span class="line">    anchors = np.vstack([_scale_enum(ratio_anchors[i, :], scales)</span><br><span class="line">                         for i in xrange(ratio_anchors.shape[0])])</span><br><span class="line">    return anchors</span><br></pre></td></tr></table></figure>
<p>生成的步骤包括：</p>
<ol>
<li>生成一个左上坐标为(0, 0), 右下坐标为(15, 15) 的<code>base_anchor</code></li>
<li>基于<code>base_anchor</code>，用<code>_ratio_enum</code>方法生成不同尺寸的anchors，默认ratios是
[0.5, 1, 2]，即3种尺寸的ratio，不同尺寸的生成框面积都是16x16，但长宽比不一样。</li>
<li>对上面每个尺寸的框，用<code>_scale_enum</code>方法再生成不同尺度的anchors，默认scales
是[8, 16, 32]，不同scale生成的框长宽比不变，但是长宽绝对值变大相应的倍数。</li>
<li>将这些生成框排列起来（np.vstack()操作）。</li>
</ol>
<p>其中，<code>_ratio_enum</code>和<code>_scale_enum</code>中都有生成anchor的操作，具体方法是
<code>_mkanchors</code>函数，根据中心点和长宽生成左上点和右下点的坐标。</p>
<h3 id="anchor-target-layer-py"><a class="header-anchor" href="#anchor-target-layer-py"></a>anchor_target_layer.py</h3>
<p>这个文件是一个类文件，继承自caffe的Layer类，caffe layer（后续简称caffe层）包括
<code>setup</code>、<code>forward</code>和<code>backward</code>函数，其中<code>setup</code>方法用来初始化一些参数，
<code>forward</code>方法定义根据输入生成输出的方法，是这一层操作的主要函数，其输出可以用做下一个caffe层的输入，而<code>backward</code>方法定义在反向传播时如何更新参数。</p>
<p><code>anchor_target_layer.py</code>目标是筛选生成的anchor，得到样本的分类标签（0/1）和标签为1的bbox的学习项，为后面计算loss提供数据。</p>
<p>首先<code>setup</code>函数将anchors坐标生成出来，<code>forward</code>函数输入是标注的框和图片信息，输出是筛选后的anchor，以及anchor的训练坐标和标签。</p>
<p>具体的方法做了这些事情：</p>
<ol>
<li>根据不同的anchors生成候选框，首先枚举了rpn分类featureMap中所有的坐标点，生成了对应原图尺寸的K*A个anchor，K是最后分类的个数，A是anchor的种类数目，即上面所说的3（不同ratio）*3（不同scale）=9个，然后保存在图像边界内的anchors。</li>
<li>计算出这些anchors和gt框的重叠，计算公式是</li>
<li>根据重叠筛选正负样本，即前背景的二分类样本，挑选规则如下：
<ol>
<li>对每个ground truth，IoU值最大的anchor，标记为正样本，label=1</li>
<li>如果anchor box与ground truth的IoU大于某阈值，标记为正样本，label=1</li>
<li>如果anchor box与ground truth的IoU小于某阈值，标记为负样本，label=0</li>
<li>正负样本如果超过一定量，则做下采样。</li>
</ol>
</li>
<li>在挑选出正负样本后，计算回归的坐标差值，并对样本设置了权重，即
<code>bbox_inside_weights</code>和<code>bbox_outside_weights</code>。</li>
<li>把采样的样本映射到原来的样本顺序(<code>_unmap</code>)，并填充<code>top</code>数据。</li>
</ol>
<h3 id="proposal-layer-py"><a class="header-anchor" href="#proposal-layer-py"></a>proposal_layer.py</h3>
<p><code>proposalLayer</code>也继承自caffe层，目标是根据分类结果生成候选框集合作为输出，
<code>setup</code>函数和上面的<code>anchor_target_layer</code>类似，也是将anchors坐标生成出来，
<code>forward</code>函数输入是rpn分类和回归的输出，以及原始图片信息，包含在<code>bottom</code>中，输出包含在<code>top</code>中，<code>top[0]</code>是筛选出的proposal的roi数据，<code>top[1]</code>是筛选出的
proposal的分数。</p>
<p>具体的方法做了这些事情：</p>
<ol>
<li>根据不同的anchors生成候选框，首先枚举了所有的点，生成了K*A个anchor，K是最后分类的个数，A是anchor的种类数目，即上面所说的3（不同ratio）*3（不同scale）
=9个，最后把bbox delta 和分类score都reshape到一样的维度。</li>
<li><code>bbox_transform_inv</code>函数根据anchor坐标和bbox delta生成proposal候选集坐标。</li>
<li><code>clip_boxes</code>函数修正超出图片大小的候选集的坐标。</li>
<li><code>_filter_boxes</code>把面积小于某个阈值的候选框筛选出去。</li>
<li>根据分类得分对候选框排序，得到分数最高的n个候选框。</li>
<li>应用nms(非极大值抑制)算法，得到分数最高的n个候选框。</li>
<li>将最后的候选框封装到<code>top</code>输出给下一层。</li>
</ol>
<h3 id="proposal-target-layer-py"><a class="header-anchor" href="#proposal-target-layer-py"></a>proposal_target_layer.py</h3>
<p><code>proposal_target_layer.py</code>也继承自caffe层，目标是为生成的proposal匹配分类标签
(1-K) 和bbox坐标学习项。</p>
<p><code>forward</code>函数输入是<code>proposal_layer</code>的输出（即候选框区域），和要学习的标注框，输出是用作训练样本的标注框和相关的学习目标（坐标差值和分类类别）。</p>
<p>在<code>proposal_layer</code>后拿到待训练的候选框之后，需要给候选框分配相应的标注，因此，主要的函数就是<code>_sample_rois</code>这个函数。</p>
<p><code>_sample_rios</code>函数步骤：</p>
<ol>
<li>计算rois和gt_boxes的重叠区域。</li>
<li>挑选重叠区域大于FG_THRESH的前景并随机挑选一些作为正样本</li>
<li>挑选重叠区域小于BG_THRESH_HI且大于BG_THRESH_LO的背景并随机挑选一些作为负样本。</li>
<li>计算挑出来的样本的bbox_data和label。</li>
</ol>
<h3 id="generate-py"><a class="header-anchor" href="#generate-py"></a><a href="http://generate.py" target="_blank" rel="noopener">generate.py</a></h3>
<p>这个文件中有两个主要的函数<code>im_proposals</code>和<code>imdb_proposals</code>，分别是将图片数据和
imdb数据传送到RPN网络得到候选集输出。这里就不详细展开了。</p>
<h2 id="总结"><a class="header-anchor" href="#总结"></a>总结</h2>
<p>根据rpn目录下的所有文件以及网络结构文件，我们再总结下rpn的框架脉络。rpn网络用来训练检测框的分类和提取，分别是用一个两层的CNN（共享第一层卷积）来做抽取，生成的维度是一个超参，也就是anchors的数量，loss是用<code>rpn_target_layer</code>筛选的样本和背景标注进行比对来计算。</p>
<p>rpn网络的分类和回归结果同时用来生成候选集proposals（<code>proposal_layer</code>和
<code>proposal_target_layer</code>），然后用<code>ROIPooling</code>生成ROIs，对每一个ROI区域做了更高维的特征提取，用来做最终的分类检测和回归检测。</p>
</div></div><script type="text/x-mathjax-config">
   MathJax.Hub.Config({"HTML-CSS": { preferredFont: "TeX", availableFonts: ["STIX","TeX"], linebreaks: { automatic:true }, EqnChunk: (MathJax.Hub.Browser.isMobile ? 10 : 50) },
        tex2jax: { inlineMath: [ ["$", "$"], ["\\(","\\)"] ], processEscapes: true, ignoreClass: "tex2jax_ignore|dno",skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']},
        TeX: {  noUndefined: { attributes: { mathcolor: "red", mathbackground: "#FFEEEE", mathsize: "90%" } }, Macros: { href: "{}" } },
        messageStyle: "none"
    }); 
</script>
<script type="text/x-mathjax-config">
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for(i=0; i < all.length; i += 1) {
            all[i].SourceElement().parentNode.className += ' has-jax';
        }
    });
</script>
<script type="text/javascript" src="https://cdn.bootcss.com/mathjax/2.7.2/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script><div class="post-main post-comment"></div></article><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/fancybox/2.1.5/jquery.fancybox.css"><script src="//cdn.bootcss.com/jquery/2.0.3/jquery.min.js"></script><script src="//cdn.bootcss.com/fancybox/2.1.5/jquery.fancybox.pack.js"></script><script>$(document).ready(function() {
  $(".fancybox").fancybox();
});
</script></body></html>